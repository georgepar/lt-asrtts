{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgepar/lt-asrtts/blob/main/Bash_For_Text_Processing_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjXt4N0Ue-4t"
      },
      "source": [
        "# Shell scripting tutorial\n",
        "\n",
        "Learning shell scripting can provide you quick and easy ways to perform a lot of work related with a machine learning / text processing project.\n",
        "\n",
        "Some of the things you can achieve with shell scripting:\n",
        "\n",
        "- Installing project dependencies\n",
        "- Build project dependencies from source\n",
        "- Download organize and clean data\n",
        "- Extract data statistics (e.g. word / character counts)\n",
        "- Perform text processing\n",
        "- Train and evaluate models using existing frameworks that provide a command line interface (Kaldi, openfst, fasttext, fairseq etc.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21X01T4Ze-4w"
      },
      "source": [
        "First of all list current working directory and it's contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XA8m9Et4e-4x",
        "outputId": "bbab7d4a-b394-4f3b-a2b5-89151df4ff0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7mM3oTJ2e-4y",
        "outputId": "55e9419e-4ebf-4853-aade-81be018bf542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16K\n",
            "drwxr-xr-x 1 root root 4.0K Apr  4 13:24 .\n",
            "drwxr-xr-x 1 root root 4.0K Apr  8 12:08 ..\n",
            "drwxr-xr-x 4 root root 4.0K Apr  4 13:24 .config\n",
            "drwxr-xr-x 1 root root 4.0K Apr  4 13:24 sample_data\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "ls -lah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNV2wwAWe-4y"
      },
      "source": [
        "## Installing project dependencies and building a project from source\n",
        "\n",
        "Let's say we need to build an N-Gram language model for some corpus. One commonly used tool for this is KenLM. Let's download and build it from source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAaTdBpue-4y"
      },
      "source": [
        "Download KenLM from git repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WewEDW2je-4y",
        "outputId": "66a2a6b7-9906-4cfc-e3ad-17b13091e336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kenlm'...\n",
            "remote: Enumerating objects: 14165, done.\u001b[K\n",
            "remote: Counting objects: 100% (478/478), done.\u001b[K\n",
            "remote: Compressing objects: 100% (332/332), done.\u001b[K\n",
            "remote: Total 14165 (delta 163), reused 409 (delta 132), pack-reused 13687\u001b[K\n",
            "Receiving objects: 100% (14165/14165), 5.91 MiB | 13.95 MiB/s, done.\n",
            "Resolving deltas: 100% (8043/8043), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kpu/kenlm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qedyBY-Ve-4z"
      },
      "source": [
        "Install necessary dependencies for building KenLM (follow docs: https://kheafield.com/code/kenlm/dependencies/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D1WaX1_de-4z",
        "outputId": "6361471f-fee6-489b-bfab-5a652a48ac64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connecting to ppa.laun\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libbz2-dev is already the newest version (1.0.8-5build1).\n",
            "liblzma-dev is already the newest version (5.2.5-2ubuntu1).\n",
            "libboost-all-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libeigen3-dev is already the newest version (3.4.0-2ubuntu2).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev libeigen3-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pqat8H-e-4z"
      },
      "source": [
        "List files in current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_tMv2y-we-40",
        "outputId": "24c7968e-df63-4cc6-cbe8-3596dea540e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20K\n",
            "drwxr-xr-x 1 root root 4.0K Apr  8 12:09 .\n",
            "drwxr-xr-x 1 root root 4.0K Apr  8 12:08 ..\n",
            "drwxr-xr-x 4 root root 4.0K Apr  4 13:24 .config\n",
            "drwxr-xr-x 8 root root 4.0K Apr  8 12:09 kenlm\n",
            "drwxr-xr-x 1 root root 4.0K Apr  4 13:24 sample_data\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "ls -lah"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "ls -lah /content/kenlm"
      ],
      "metadata": {
        "id": "B_hX0As6hOji",
        "outputId": "748ef0ed-376a-4189-c9bf-772e8567f26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 220K\n",
            "drwxr-xr-x 8 root root 4.0K Apr  8 12:09 .\n",
            "drwxr-xr-x 1 root root 4.0K Apr  8 12:09 ..\n",
            "-rw-r--r-- 1 root root  696 Apr  8 12:09 BUILDING\n",
            "-rwxr-xr-x 1 root root   81 Apr  8 12:09 clean_query_only.sh\n",
            "drwxr-xr-x 3 root root 4.0K Apr  8 12:09 cmake\n",
            "-rw-r--r-- 1 root root 4.7K Apr  8 12:09 CMakeLists.txt\n",
            "-rwxr-xr-x 1 root root 1.2K Apr  8 12:09 compile_query_only.sh\n",
            "-rw-r--r-- 1 root root  26K Apr  8 12:09 COPYING\n",
            "-rw-r--r-- 1 root root  35K Apr  8 12:09 COPYING.3\n",
            "-rw-r--r-- 1 root root 7.5K Apr  8 12:09 COPYING.LESSER.3\n",
            "-rw-r--r-- 1 root root  63K Apr  8 12:09 Doxyfile\n",
            "drwxr-xr-x 8 root root 4.0K Apr  8 12:09 .git\n",
            "drwxr-xr-x 3 root root 4.0K Apr  8 12:09 .github\n",
            "-rw-r--r-- 1 root root  261 Apr  8 12:09 .gitignore\n",
            "-rw-r--r-- 1 root root 1.2K Apr  8 12:09 LICENSE\n",
            "drwxr-xr-x 7 root root 4.0K Apr  8 12:09 lm\n",
            "-rw-r--r-- 1 root root  220 Apr  8 12:09 MANIFEST.in\n",
            "-rw-r--r-- 1 root root   59 Apr  8 12:09 pyproject.toml\n",
            "drwxr-xr-x 2 root root 4.0K Apr  8 12:09 python\n",
            "-rw-r--r-- 1 root root 5.9K Apr  8 12:09 README.md\n",
            "-rw-r--r-- 1 root root 4.4K Apr  8 12:09 setup.py\n",
            "drwxr-xr-x 4 root root 4.0K Apr  8 12:09 util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA9Vylo3e-40"
      },
      "source": [
        "Navigate inside kenlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7KQ8-rDMe-40"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "mkdir -p /content/kenlm/build"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "ls -lah /content/kenlm"
      ],
      "metadata": {
        "id": "ZqxLq17whWYW",
        "outputId": "bad1df43-58b8-4054-c746-e1618b96d57e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 224K\n",
            "drwxr-xr-x 9 root root 4.0K Apr  8 12:10 .\n",
            "drwxr-xr-x 1 root root 4.0K Apr  8 12:09 ..\n",
            "drwxr-xr-x 2 root root 4.0K Apr  8 12:10 build\n",
            "-rw-r--r-- 1 root root  696 Apr  8 12:09 BUILDING\n",
            "-rwxr-xr-x 1 root root   81 Apr  8 12:09 clean_query_only.sh\n",
            "drwxr-xr-x 3 root root 4.0K Apr  8 12:09 cmake\n",
            "-rw-r--r-- 1 root root 4.7K Apr  8 12:09 CMakeLists.txt\n",
            "-rwxr-xr-x 1 root root 1.2K Apr  8 12:09 compile_query_only.sh\n",
            "-rw-r--r-- 1 root root  26K Apr  8 12:09 COPYING\n",
            "-rw-r--r-- 1 root root  35K Apr  8 12:09 COPYING.3\n",
            "-rw-r--r-- 1 root root 7.5K Apr  8 12:09 COPYING.LESSER.3\n",
            "-rw-r--r-- 1 root root  63K Apr  8 12:09 Doxyfile\n",
            "drwxr-xr-x 8 root root 4.0K Apr  8 12:09 .git\n",
            "drwxr-xr-x 3 root root 4.0K Apr  8 12:09 .github\n",
            "-rw-r--r-- 1 root root  261 Apr  8 12:09 .gitignore\n",
            "-rw-r--r-- 1 root root 1.2K Apr  8 12:09 LICENSE\n",
            "drwxr-xr-x 7 root root 4.0K Apr  8 12:09 lm\n",
            "-rw-r--r-- 1 root root  220 Apr  8 12:09 MANIFEST.in\n",
            "-rw-r--r-- 1 root root   59 Apr  8 12:09 pyproject.toml\n",
            "drwxr-xr-x 2 root root 4.0K Apr  8 12:09 python\n",
            "-rw-r--r-- 1 root root 5.9K Apr  8 12:09 README.md\n",
            "-rw-r--r-- 1 root root 4.4K Apr  8 12:09 setup.py\n",
            "drwxr-xr-x 4 root root 4.0K Apr  8 12:09 util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LRdeHMGe-40"
      },
      "source": [
        "Display current working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j2p3StBe-40"
      },
      "source": [
        "Use cmake to compile project (follow instructions: https://github.com/kpu/kenlm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RW2Hn8rte-41",
        "outputId": "59471f57-a138-479d-ff86-ba100d166512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Configuring done (2.2s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-to-string.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/string-to-double.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 32%] Built target kenlm_util\n",
            "[ 33%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 43%] Built target kenlm_filter\n",
            "[ 44%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 51%] Built target probing_hash_table_benchmark\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 59%] Built target kenlm\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 64%] Built target fragment\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 66%] Built target build_binary\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 68%] Built target query\n",
            "[ 69%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 71%] Built target phrase_table_vocab\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/backoff_reunification.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/bounded_sequence_encoding.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/merge_probabilities.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/merge_vocab.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/normalize.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 80%] Built target kenlm_benchmark\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/pipeline.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 83%] Built target filter\n",
            "[ 84%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/split_worker.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/tune_derivatives.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/tune_instances.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/tune_weights.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/kenlm_interpolate.dir/universal_vocab.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 90%] Built target kenlm_builder\n",
            "[ 91%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_interpolate.a\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 94%] Built target kenlm_interpolate\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/streaming_example.dir/streaming_example_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object lm/interpolate/CMakeFiles/interpolate.dir/interpolate_main.cc.o\u001b[0m\n",
            "[ 96%] Built target lmplz\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[ 97%] Built target count_ngrams\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/interpolate\u001b[0m\n",
            "[ 98%] Built target interpolate\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/streaming_example\u001b[0m\n",
            "[100%] Built target streaming_example\n"
          ]
        }
      ],
      "source": [
        "!cd /content/kenlm/build && cmake .. && make -j4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "ls -lah /content/kenlm/build/bin"
      ],
      "metadata": {
        "id": "xPgLzg71fZpp",
        "outputId": "843e7c5b-e868-41e0-a5c0-cd5d16d6b82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8.2M\n",
            "drwxr-xr-x 2 root root 4.0K Apr  8 12:13 .\n",
            "drwxr-xr-x 7 root root 4.0K Apr  8 12:10 ..\n",
            "-rwxr-xr-x 1 root root 728K Apr  8 12:11 build_binary\n",
            "-rwxr-xr-x 1 root root 612K Apr  8 12:13 count_ngrams\n",
            "-rwxr-xr-x 1 root root 749K Apr  8 12:12 filter\n",
            "-rwxr-xr-x 1 root root 695K Apr  8 12:11 fragment\n",
            "-rwxr-xr-x 1 root root 1.2M Apr  8 12:13 interpolate\n",
            "-rwxr-xr-x 1 root root 1.2M Apr  8 12:12 kenlm_benchmark\n",
            "-rwxr-xr-x 1 root root 1.5M Apr  8 12:13 lmplz\n",
            "-rwxr-xr-x 1 root root 199K Apr  8 12:12 phrase_table_vocab\n",
            "-rwxr-xr-x 1 root root 306K Apr  8 12:11 probing_hash_table_benchmark\n",
            "-rwxr-xr-x 1 root root 747K Apr  8 12:12 query\n",
            "-rwxr-xr-x 1 root root 505K Apr  8 12:13 streaming_example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjw2BCNze-41"
      },
      "source": [
        "The previous commands built the KenLM binaries inside the bin folder. Let's copy it in a more accessible directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ek_z3n3Ne-41",
        "outputId": "0d95a882-28ae-40bf-a2cb-25368798de53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 32%] Built target kenlm_util\n",
            "[ 34%] Built target probing_hash_table_benchmark\n",
            "[ 55%] Built target kenlm\n",
            "[ 57%] Built target query\n",
            "[ 59%] Built target fragment\n",
            "[ 61%] Built target build_binary\n",
            "[ 63%] Built target kenlm_benchmark\n",
            "[ 70%] Built target kenlm_builder\n",
            "[ 72%] Built target lmplz\n",
            "[ 75%] Built target count_ngrams\n",
            "[ 79%] Built target kenlm_filter\n",
            "[ 81%] Built target filter\n",
            "[ 83%] Built target phrase_table_vocab\n",
            "[ 95%] Built target kenlm_interpolate\n",
            "[ 97%] Built target interpolate\n",
            "[100%] Built target streaming_example\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"Release\"\n",
            "-- Installing: /usr/local/share/kenlm/cmake/kenlmTargets.cmake\n",
            "-- Installing: /usr/local/share/kenlm/cmake/kenlmTargets-release.cmake\n",
            "-- Installing: /usr/local/include/kenlm/util/bit_packing.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/ersatz_progress.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/exception.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/fake_ostream.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/file.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/file_piece.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/file_stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/fixed_array.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/float_to_string.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/getopt.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/have.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/integer_to_string.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/joint_sort.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/mmap.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/multi_intersection.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/murmur_hash.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/parallel_read.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/pcqueue.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/pool.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/probing_hash_table.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/proxy_iterator.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/read_compressed.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/scoped.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/sized_iterator.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/sorted_uniform.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/spaces.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/string_piece.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/string_piece_hash.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/string_stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/thread_pool.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/tokenize_piece.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/usage.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/bignum-dtoa.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/bignum.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/cached-powers.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/diy-fp.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/double-conversion.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/double-to-string.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/fast-dtoa.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/fixed-dtoa.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/ieee.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/string-to-double.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/strtod.h\n",
            "-- Installing: /usr/local/include/kenlm/util/double-conversion/utils.h\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/block.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/chain.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/config.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/count_records.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/io.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/line_input.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/multi_progress.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/multi_stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/rewindable_stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/sort.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/util/stream/typed_stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/bhiksha.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/binary_format.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/blank.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/config.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/enumerate_vocab.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/facade.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/left.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/lm_exception.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/max_order.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/model.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/model_type.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/ngram_query.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/partial.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/quantize.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/read_arpa.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/return.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/search_hashed.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/search_trie.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/sizes.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/state.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/trie.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/trie_sort.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/value.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/value_build.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/virtual_interface.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/vocab.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/weights.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/word_index.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/adjust_counts.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/combine_counts.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/corpus_count.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/debug_print.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/discount.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/hash_gamma.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/header_info.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/initial_probabilities.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/interpolate.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/output.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/payload.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/builder/pipeline.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/compare.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/joint_order.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/model_buffer.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/ngram.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/ngram_stream.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/print.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/renumber.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/size_option.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/common/special.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/arpa_io.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/count_io.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/format.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/phrase.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/thread.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/vocab.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/filter/wrapper.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/backoff_matrix.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/backoff_reunification.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/bounded_sequence_encoding.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/interpolate_info.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/merge_probabilities.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/merge_vocab.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/normalize.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/pipeline.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/split_worker.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/tune_derivatives.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/tune_instances.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/tune_matrix.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/tune_weights.hh\n",
            "-- Installing: /usr/local/include/kenlm/lm/interpolate/universal_vocab.hh\n",
            "-- Installing: /usr/local/share/kenlm/cmake/kenlmConfig.cmake\n",
            "-- Installing: /usr/local/lib/libkenlm_util.a\n",
            "-- Installing: /usr/local/bin/probing_hash_table_benchmark\n",
            "-- Installing: /usr/local/lib/libkenlm.a\n",
            "-- Installing: /usr/local/bin/query\n",
            "-- Installing: /usr/local/bin/fragment\n",
            "-- Installing: /usr/local/bin/build_binary\n",
            "-- Installing: /usr/local/bin/kenlm_benchmark\n",
            "-- Installing: /usr/local/bin/lmplz\n",
            "-- Installing: /usr/local/bin/count_ngrams\n",
            "-- Installing: /usr/local/lib/libkenlm_builder.a\n",
            "-- Installing: /usr/local/bin/filter\n",
            "-- Installing: /usr/local/bin/phrase_table_vocab\n",
            "-- Installing: /usr/local/lib/libkenlm_filter.a\n",
            "-- Installing: /usr/local/bin/interpolate\n",
            "-- Installing: /usr/local/bin/streaming_example\n",
            "-- Installing: /usr/local/lib/libkenlm_interpolate.a\n"
          ]
        }
      ],
      "source": [
        "!cd /content/kenlm/build && sudo make install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wa5XoPTue-41",
        "outputId": "827777eb-1e20-4388-9a48-25af6271ce00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Builds unpruned language models with modified Kneser-Ney smoothing.\n",
            "\n",
            "Please cite:\n",
            "@inproceedings{Heafield-estimate,\n",
            "  author = {Kenneth Heafield and Ivan Pouzyrevsky and Jonathan H. Clark and Philipp Koehn},\n",
            "  title = {Scalable Modified {Kneser-Ney} Language Model Estimation},\n",
            "  year = {2013},\n",
            "  month = {8},\n",
            "  booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics},\n",
            "  address = {Sofia, Bulgaria},\n",
            "  url = {http://kheafield.com/professional/edinburgh/estimate\\_paper.pdf},\n",
            "}\n",
            "\n",
            "Provide the corpus on stdin.  The ARPA file will be written to stdout.  Order of\n",
            "the model (-o) is the only mandatory option.  As this is an on-disk program,\n",
            "setting the temporary file location (-T) and sorting memory (-S) is recommended.\n",
            "\n",
            "Memory sizes are specified like GNU sort: a number followed by a unit character.\n",
            "Valid units are % for percentage of memory (supported platforms only) and (in\n",
            "increasing powers of 1024): b, K, M, G, T, P, E, Z, Y.  Default is K (*1024).\n",
            "This machine has 13609451520 bytes of memory.\n",
            "\n",
            "Language model building options:\n",
            "  -h [ --help ]                         Show this help message\n",
            "  -o [ --order ] arg                    Order of the model\n",
            "  --interpolate_unigrams [=arg(=1)] (=1)\n",
            "                                        Interpolate the unigrams (default) as \n",
            "                                        opposed to giving lots of mass to <unk>\n",
            "                                        like SRI.  If you want SRI's behavior \n",
            "                                        with a large <unk> and the old lmplz \n",
            "                                        default, use --interpolate_unigrams 0.\n",
            "  --skip_symbols                        Treat <s>, </s>, and <unk> as \n",
            "                                        whitespace instead of throwing an \n",
            "                                        exception\n",
            "  -T [ --temp_prefix ] arg (=/tmp/)     Temporary file prefix\n",
            "  -S [ --memory ] arg (=80%)            Sorting memory\n",
            "  --minimum_block arg (=8K)             Minimum block size to allow\n",
            "  --sort_block arg (=64M)               Size of IO operations for sort \n",
            "                                        (determines arity)\n",
            "  --block_count arg (=2)                Block count (per order)\n",
            "  --vocab_estimate arg (=1000000)       Assume this vocabulary size for \n",
            "                                        purposes of calculating memory in step \n",
            "                                        1 (corpus count) and pre-sizing the \n",
            "                                        hash table\n",
            "  --vocab_pad arg (=0)                  If the vocabulary is smaller than this \n",
            "                                        value, pad with <unk> to reach this \n",
            "                                        size. Requires --interpolate_unigrams\n",
            "  --verbose_header                      Add a verbose header to the ARPA file \n",
            "                                        that includes information such as token\n",
            "                                        count, smoothing type, etc.\n",
            "  --text arg                            Read text from a file instead of stdin\n",
            "  --arpa arg                            Write ARPA to a file instead of stdout\n",
            "  --intermediate arg                    Write ngrams to intermediate files.  \n",
            "                                        Turns off ARPA output (which can be \n",
            "                                        reactivated by --arpa file).  Forces \n",
            "                                        --renumber on.\n",
            "  --renumber                            Renumber the vocabulary identifiers so \n",
            "                                        that they are monotone with the hash of\n",
            "                                        each string.  This is consistent with \n",
            "                                        the ordering used by the trie data \n",
            "                                        structure.\n",
            "  --collapse_values                     Collapse probability and backoff into a\n",
            "                                        single value, q that yields the same \n",
            "                                        sentence-level probabilities.  See \n",
            "                                        http://kheafield.com/professional/edinb\n",
            "                                        urgh/rest_paper.pdf for more details, \n",
            "                                        including a proof.\n",
            "  --prune arg                           Prune n-grams with count less than or \n",
            "                                        equal to the given threshold.  Specify \n",
            "                                        one value for each order i.e. 0 0 1 to \n",
            "                                        prune singleton trigrams and above.  \n",
            "                                        The sequence of values must be \n",
            "                                        non-decreasing and the last value \n",
            "                                        applies to any remaining orders. \n",
            "                                        Default is to not prune, which is \n",
            "                                        equivalent to --prune 0.\n",
            "  --limit_vocab_file arg                Read allowed vocabulary separated by \n",
            "                                        whitespace. N-grams that contain \n",
            "                                        vocabulary items not in this list will \n",
            "                                        be pruned. Can be combined with --prune\n",
            "                                        arg\n",
            "  --discount_fallback [=arg(=0.5 1 1.5)]\n",
            "                                        The closed-form estimate for Kneser-Ney\n",
            "                                        discounts does not work without \n",
            "                                        singletons or doubletons.  It can also \n",
            "                                        fail if these values are out of range. \n",
            "                                        This option falls back to \n",
            "                                        user-specified discounts when the \n",
            "                                        closed-form estimate fails.  Note that \n",
            "                                        this option is generally a bad idea: \n",
            "                                        you should deduplicate your corpus \n",
            "                                        instead.  However, class-based models \n",
            "                                        need custom discounts because they lack\n",
            "                                        singleton unigrams.  Provide up to \n",
            "                                        three discounts (for adjusted counts 1,\n",
            "                                        2, and 3+), which will be applied to \n",
            "                                        all orders where the closed-form \n",
            "                                        estimates fail.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lmplz --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA8Lzep_e-41"
      },
      "source": [
        "## Download and preprocessing training corpus\n",
        "\n",
        "Let's get a book from project gutenberg and clean it up using bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bYMsUCdEe-41",
        "outputId": "52456a80-15da-44a9-bb0a-7bce36d7e70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2024-04-08 12:29:09--  http://www.gutenberg.org/cache/epub/345/pg345.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.gutenberg.org/cache/epub/345/pg345.txt [following]\n",
            "--2024-04-08 12:29:09--  https://www.gutenberg.org/cache/epub/345/pg345.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 890394 (870K) [text/plain]\n",
            "Saving to: data/dracula.txt\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  5% 3.03M 0s\n",
            "    50K .......... .......... .......... .......... .......... 11% 3.17M 0s\n",
            "   100K .......... .......... .......... .......... .......... 17% 98.8M 0s\n",
            "   150K .......... .......... .......... .......... .......... 23% 3.31M 0s\n",
            "   200K .......... .......... .......... .......... .......... 28% 60.6M 0s\n",
            "   250K .......... .......... .......... .......... .......... 34%  127M 0s\n",
            "   300K .......... .......... .......... .......... .......... 40%  197M 0s\n",
            "   350K .......... .......... .......... .......... .......... 46%  172M 0s\n",
            "   400K .......... .......... .......... .......... .......... 51% 3.44M 0s\n",
            "   450K .......... .......... .......... .......... .......... 57%  143M 0s\n",
            "   500K .......... .......... .......... .......... .......... 63% 73.1M 0s\n",
            "   550K .......... .......... .......... .......... .......... 69%  211M 0s\n",
            "   600K .......... .......... .......... .......... .......... 74%  180M 0s\n",
            "   650K .......... .......... .......... .......... .......... 80%  213M 0s\n",
            "   700K .......... .......... .......... .......... .......... 86%  172M 0s\n",
            "   750K .......... .......... .......... .......... .......... 92%  200M 0s\n",
            "   800K .......... .......... .......... .......... .......... 97%  205M 0s\n",
            "   850K .......... .........                                  100% 1.48M=0.08s\n",
            "\n",
            "2024-04-08 12:29:10 (10.9 MB/s) - data/dracula.txt saved [890394/890394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "mkdir data\n",
        "wget -O data/dracula.txt http://www.gutenberg.org/cache/epub/345/pg345.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hy16ztble-41",
        "outputId": "32d0d9d9-e525-4ba0-c01b-aeca1179f53b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 880K\n",
            "drwxr-xr-x 2 root root 4.0K Apr  8 12:29 .\n",
            "drwxr-xr-x 1 root root 4.0K Apr  8 12:29 ..\n",
            "-rw-r--r-- 1 root root 870K Apr  1 09:06 dracula.txt\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "ls -lah data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRI5CSIHe-42"
      },
      "source": [
        "Count the number of lines, words and characters using wc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1sGj2TRIe-42",
        "outputId": "1885b489-3c4a-4952-ef9d-da98073f5d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15851 data/dracula.txt\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "wc -l data/dracula.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VsFv-hRe-42"
      },
      "source": [
        "We can format column printing using awk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8YU6Ad5We-42",
        "outputId": "686686ab-df51-4389-f160-5ebea1fa831c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/dracula.txt contains 15851 lines\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "wc -l data/dracula.txt | awk '{printf \"%s contains %s lines\\n\", $2, $1}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KPpdbcJGe-42",
        "outputId": "f0148b12-29b3-45f6-b009-c3789561aa93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/dracula.txt contains 164351 words\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "wc -w data/dracula.txt | awk '{printf \"%s contains %s words\\n\", $2, $1}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PdpU6Ddwe-42",
        "outputId": "785c5a0d-5ee5-4862-f73f-5397bc4d9dc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/dracula.txt contains 890394 characters\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "wc -c data/dracula.txt | awk '{printf \"%s contains %s characters\\n\", $2, $1}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r7teyF_e-42"
      },
      "source": [
        "Inspect the first 250 lines using head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OnBqregze-42",
        "outputId": "a65bead6-23f3-4e1e-8e63-b6e381192fe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Project Gutenberg eBook of Dracula\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this ebook or online\r\n",
            "at www.gutenberg.org. If you are not located in the United States,\r\n",
            "you will have to check the laws of the country where you are located\r\n",
            "before using this eBook.\r\n",
            "\r\n",
            "Title: Dracula\r\n",
            "\r\n",
            "Author: Bram Stoker\r\n",
            "\r\n",
            "Release date: October 1, 1995 [eBook #345]\r\n",
            "                Most recently updated: November 12, 2023\r\n",
            "\r\n",
            "Language: English\r\n",
            "\r\n",
            "Credits: Chuck Greif and the Online Distributed Proofreading Team\r\n",
            "\r\n",
            "\r\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK DRACULA ***\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "                                DRACULA\r\n",
            "\r\n",
            "                                  _by_\r\n",
            "\r\n",
            "                              Bram Stoker\r\n",
            "\r\n",
            "                        [Illustration: colophon]\r\n",
            "\r\n",
            "                                NEW YORK\r\n",
            "\r\n",
            "                            GROSSET & DUNLAP\r\n",
            "\r\n",
            "                              _Publishers_\r\n",
            "\r\n",
            "      Copyright, 1897, in the United States of America, according\r\n",
            "                   to Act of Congress, by Bram Stoker\r\n",
            "\r\n",
            "                        [_All rights reserved._]\r\n",
            "\r\n",
            "                      PRINTED IN THE UNITED STATES\r\n",
            "                                   AT\r\n",
            "               THE COUNTRY LIFE PRESS, GARDEN CITY, N.Y.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "                                   TO\r\n",
            "\r\n",
            "                             MY DEAR FRIEND\r\n",
            "\r\n",
            "                               HOMMY-BEG\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Contents\r\n",
            "\r\n",
            "CHAPTER I. Jonathan Harkers Journal\r\n",
            "CHAPTER II. Jonathan Harkers Journal\r\n",
            "CHAPTER III. Jonathan Harkers Journal\r\n",
            "CHAPTER IV. Jonathan Harkers Journal\r\n",
            "CHAPTER V. LettersLucy and Mina\r\n",
            "CHAPTER VI. Mina Murrays Journal\r\n",
            "CHAPTER VII. Cutting from The Dailygraph, 8 August\r\n",
            "CHAPTER VIII. Mina Murrays Journal\r\n",
            "CHAPTER IX. Mina Murrays Journal\r\n",
            "CHAPTER X. Mina Murrays Journal\r\n",
            "CHAPTER XI. Lucy Westenras Diary\r\n",
            "CHAPTER XII. Dr. Sewards Diary\r\n",
            "CHAPTER XIII. Dr. Sewards Diary\r\n",
            "CHAPTER XIV. Mina Harkers Journal\r\n",
            "CHAPTER XV. Dr. Sewards Diary\r\n",
            "CHAPTER XVI. Dr. Sewards Diary\r\n",
            "CHAPTER XVII. Dr. Sewards Diary\r\n",
            "CHAPTER XVIII. Dr. Sewards Diary\r\n",
            "CHAPTER XIX. Jonathan Harkers Journal\r\n",
            "CHAPTER XX. Jonathan Harkers Journal\r\n",
            "CHAPTER XXI. Dr. Sewards Diary\r\n",
            "CHAPTER XXII. Jonathan Harkers Journal\r\n",
            "CHAPTER XXIII. Dr. Sewards Diary\r\n",
            "CHAPTER XXIV. Dr. Sewards Phonograph Diary, spoken by Van Helsing\r\n",
            "CHAPTER XXV. Dr. Sewards Diary\r\n",
            "CHAPTER XXVI. Dr. Sewards Diary\r\n",
            "CHAPTER XXVII. Mina Harkers Journal\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "How these papers have been placed in sequence will be made manifest in\r\n",
            "the reading of them. All needless matters have been eliminated, so that\r\n",
            "a history almost at variance with the possibilities of later-day belief\r\n",
            "may stand forth as simple fact. There is throughout no statement of\r\n",
            "past things wherein memory may err, for all the records chosen are\r\n",
            "exactly contemporary, given from the standpoints and within the range\r\n",
            "of knowledge of those who made them.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "DRACULA\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "CHAPTER I\r\n",
            "\r\n",
            "JONATHAN HARKERS JOURNAL\r\n",
            "\r\n",
            "(_Kept in shorthand._)\r\n",
            "\r\n",
            "\r\n",
            "_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at\r\n",
            "Vienna early next morning; should have arrived at 6:46, but train was an\r\n",
            "hour late. Buda-Pesth seems a wonderful place, from the glimpse which I\r\n",
            "got of it from the train and the little I could walk through the\r\n",
            "streets. I feared to go very far from the station, as we had arrived\r\n",
            "late and would start as near the correct time as possible. The\r\n",
            "impression I had was that we were leaving the West and entering the\r\n",
            "East; the most western of splendid bridges over the Danube, which is\r\n",
            "here of noble width and depth, took us among the traditions of Turkish\r\n",
            "rule.\r\n",
            "\r\n",
            "We left in pretty good time, and came after nightfall to Klausenburgh.\r\n",
            "Here I stopped for the night at the Hotel Royale. I had for dinner, or\r\n",
            "rather supper, a chicken done up some way with red pepper, which was\r\n",
            "very good but thirsty. (_Mem._, get recipe for Mina.) I asked the\r\n",
            "waiter, and he said it was called paprika hendl, and that, as it was a\r\n",
            "national dish, I should be able to get it anywhere along the\r\n",
            "Carpathians. I found my smattering of German very useful here; indeed, I\r\n",
            "dont know how I should be able to get on without it.\r\n",
            "\r\n",
            "Having had some time at my disposal when in London, I had visited the\r\n",
            "British Museum, and made search among the books and maps in the library\r\n",
            "regarding Transylvania; it had struck me that some foreknowledge of the\r\n",
            "country could hardly fail to have some importance in dealing with a\r\n",
            "nobleman of that country. I find that the district he named is in the\r\n",
            "extreme east of the country, just on the borders of three states,\r\n",
            "Transylvania, Moldavia and Bukovina, in the midst of the Carpathian\r\n",
            "mountains; one of the wildest and least known portions of Europe. I was\r\n",
            "not able to light on any map or work giving the exact locality of the\r\n",
            "Castle Dracula, as there are no maps of this country as yet to compare\r\n",
            "with our own Ordnance Survey maps; but I found that Bistritz, the post\r\n",
            "town named by Count Dracula, is a fairly well-known place. I shall enter\r\n",
            "here some of my notes, as they may refresh my memory when I talk over my\r\n",
            "travels with Mina.\r\n",
            "\r\n",
            "In the population of Transylvania there are four distinct nationalities:\r\n",
            "Saxons in the South, and mixed with them the Wallachs, who are the\r\n",
            "descendants of the Dacians; Magyars in the West, and Szekelys in the\r\n",
            "East and North. I am going among the latter, who claim to be descended\r\n",
            "from Attila and the Huns. This may be so, for when the Magyars conquered\r\n",
            "the country in the eleventh century they found the Huns settled in it. I\r\n",
            "read that every known superstition in the world is gathered into the\r\n",
            "horseshoe of the Carpathians, as if it were the centre of some sort of\r\n",
            "imaginative whirlpool; if so my stay may be very interesting. (_Mem._, I\r\n",
            "must ask the Count all about them.)\r\n",
            "\r\n",
            "I did not sleep well, though my bed was comfortable enough, for I had\r\n",
            "all sorts of queer dreams. There was a dog howling all night under my\r\n",
            "window, which may have had something to do with it; or it may have been\r\n",
            "the paprika, for I had to drink up all the water in my carafe, and was\r\n",
            "still thirsty. Towards morning I slept and was wakened by the continuous\r\n",
            "knocking at my door, so I guess I must have been sleeping soundly then.\r\n",
            "I had for breakfast more paprika, and a sort of porridge of maize flour\r\n",
            "which they said was mamaliga, and egg-plant stuffed with forcemeat, a\r\n",
            "very excellent dish, which they call impletata. (_Mem._, get recipe\r\n",
            "for this also.) I had to hurry breakfast, for the train started a little\r\n",
            "before eight, or rather it ought to have done so, for after rushing to\r\n",
            "the station at 7:30 I had to sit in the carriage for more than an hour\r\n",
            "before we began to move. It seems to me that the further east you go the\r\n",
            "more unpunctual are the trains. What ought they to be in China?\r\n",
            "\r\n",
            "All day long we seemed to dawdle through a country which was full of\r\n",
            "beauty of every kind. Sometimes we saw little towns or castles on the\r\n",
            "top of steep hills such as we see in old missals; sometimes we ran by\r\n",
            "rivers and streams which seemed from the wide stony margin on each side\r\n",
            "of them to be subject to great floods. It takes a lot of water, and\r\n",
            "running strong, to sweep the outside edge of a river clear. At every\r\n",
            "station there were groups of people, sometimes crowds, and in all sorts\r\n",
            "of attire. Some of them were just like the peasants at home or those I\r\n",
            "saw coming through France and Germany, with short jackets and round hats\r\n",
            "and home-made trousers; but others were very picturesque. The women\r\n",
            "looked pretty, except when you got near them, but they were very clumsy\r\n",
            "about the waist. They had all full white sleeves of some kind or other,\r\n",
            "and most of them had big belts with a lot of strips of something\r\n",
            "fluttering from them like the dresses in a ballet, but of course there\r\n",
            "were petticoats under them. The strangest figures we saw were the\r\n",
            "Slovaks, who were more barbarian than the rest, with their big cow-boy\r\n",
            "hats, great baggy dirty-white trousers, white linen shirts, and enormous\r\n",
            "heavy leather belts, nearly a foot wide, all studded over with brass\r\n",
            "nails. They wore high boots, with their trousers tucked into them, and\r\n",
            "had long black hair and heavy black moustaches. They are very\r\n",
            "picturesque, but do not look prepossessing. On the stage they would be\r\n",
            "set down at once as some old Oriental band of brigands. They are,\r\n",
            "however, I am told, very harmless and rather wanting in natural\r\n",
            "self-assertion.\r\n",
            "\r\n",
            "It was on the dark side of twilight when we got to Bistritz, which is a\r\n",
            "very interesting old place. Being practically on the frontier--for the\r\n",
            "Borgo Pass leads from it into Bukovina--it has had a very stormy\r\n",
            "existence, and it certainly shows marks of it. Fifty years ago a series\r\n",
            "of great fires took place, which made terrible havoc on five separate\r\n",
            "occasions. At the very beginning of the seventeenth century it underwent\r\n",
            "a siege of three weeks and lost 13,000 people, the casualties of war\r\n",
            "proper being assisted by famine and disease.\r\n",
            "\r\n",
            "Count Dracula had directed me to go to the Golden Krone Hotel, which I\r\n",
            "found, to my great delight, to be thoroughly old-fashioned, for of\r\n",
            "course I wanted to see all I could of the ways of the country. I was\r\n",
            "evidently expected, for when I got near the door I faced a\r\n",
            "cheery-looking elderly woman in the usual peasant dress--white\r\n",
            "undergarment with long double apron, front, and back, of coloured stuff\r\n",
            "fitting almost too tight for modesty. When I came close she bowed and\r\n",
            "said, The Herr Englishman? Yes, I said, Jonathan Harker. She\r\n",
            "smiled, and gave some message to an elderly man in white shirt-sleeves,\r\n",
            "who had followed her to the door. He went, but immediately returned with\r\n",
            "a letter:--\r\n",
            "\r\n",
            "     My Friend.--Welcome to the Carpathians. I am anxiously expecting\r\n",
            "     you. Sleep well to-night. At three to-morrow the diligence will\r\n",
            "     start for Bukovina; a place on it is kept for you. At the Borgo\r\n",
            "     Pass my carriage will await you and will bring you to me. I trust\r\n",
            "     that your journey from London has been a happy one, and that you\r\n",
            "     will enjoy your stay in my beautiful land.\r\n",
            "\r\n",
            "Your friend,\r\n",
            "\r\n",
            "DRACULA.\r\n",
            "\r\n",
            "\r\n",
            "_4 May._--I found that my landlord had got a letter from the Count,\r\n",
            "directing him to secure the best place on the coach for me; but on\r\n",
            "making inquiries as to details he seemed somewhat reticent, and\r\n",
            "pretended that he could not understand my German. This could not be\r\n",
            "true, because up to then he had understood it perfectly; at least, he\r\n",
            "answered my questions exactly as if he did. He and his wife, the old\r\n",
            "lady who had received me, looked at each other in a frightened sort of\r\n",
            "way. He mumbled out that the money had been sent in a letter, and that\r\n",
            "was all he knew. When I asked him if he knew Count Dracula, and could\r\n",
            "tell me anything of his castle, both he and his wife crossed themselves,\r\n",
            "and, saying that they knew nothing at all, simply refused to speak\r\n",
            "further. It was so near the time of starting that I had no time to ask\r\n",
            "any one else, for it was all very mysterious and not by any means\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "head -250 data/dracula.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfOsno9Be-42"
      },
      "source": [
        "We see that the first 200 lines contain project gutenberg specific text and the tableof contents. We can remove these using sed. Then we inspect the new file using head and wc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T_ohO9SEe-43",
        "outputId": "23b2b02b-6e96-45a2-d8a1-48cf13b7db04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "DRACULA\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "CHAPTER I\r\n",
            "\r\n",
            "JONATHAN HARKERS JOURNAL\r\n",
            "\r\n",
            "(_Kept in shorthand._)\r\n",
            "\r\n",
            "\r\n",
            "_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at\r\n",
            "Vienna early next morning; should have arrived at 6:46, but train was an\r\n",
            "hour late. Buda-Pesth seems a wonderful place, from the glimpse which I\r\n",
            "got of it from the train and the little I could walk through the\r\n",
            "streets. I feared to go very far from the station, as we had arrived\r\n",
            "late and would start as near the correct time as possible. The\r\n",
            "impression I had was that we were leaving the West and entering the\r\n",
            "East; the most western of splendid bridges over the Danube, which is\r\n",
            "here of noble width and depth, took us among the traditions of Turkish\r\n",
            "rule.\r\n",
            "\r\n",
            "We left in pretty good time, and came after nightfall to Klausenburgh.\r\n",
            "Here I stopped for the night at the Hotel Royale. I had for dinner, or\r\n",
            "rather supper, a chicken done up some way with red pepper, which was\r\n",
            "very good but thirsty. (_Mem._, get recipe for Mina.) I asked the\r\n",
            "waiter, and he said it was called paprika hendl, and that, as it was a\r\n",
            "national dish, I should be able to get it anywhere along the\r\n",
            "Carpathians. I found my smattering of German very useful here; indeed, I\r\n",
            "dont know how I should be able to get on without it.\r\n",
            "\r\n",
            "Having had some time at my disposal when in London, I had visited the\r\n",
            "British Museum, and made search among the books and maps in the library\r\n",
            "regarding Transylvania; it had struck me that some foreknowledge of the\r\n",
            "country could hardly fail to have some importance in dealing with a\r\n",
            "nobleman of that country. I find that the district he named is in the\r\n",
            "extreme east of the country, just on the borders of three states,\r\n",
            "Transylvania, Moldavia and Bukovina, in the midst of the Carpathian\r\n",
            "mountains; one of the wildest and least known portions of Europe. I was\r\n",
            "not able to light on any map or work giving the exact locality of the\r\n",
            "Castle Dracula, as there are no maps of this country as yet to compare\r\n",
            "with our own Ordnance Survey maps; but I found that Bistritz, the post\r\n",
            "town named by Count Dracula, is a fairly well-known place. I shall enter\r\n",
            "here some of my notes, as they may refresh my memory when I talk over my\r\n",
            "travels with Mina.\r\n",
            "\r\n",
            "In the population of Transylvania there are four distinct nationalities:\r\n",
            "Saxons in the South, and mixed with them the Wallachs, who are the\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "sed -e \"1,105d\" data/dracula.txt > data/dracula1.txt\n",
        "head -50 data/dracula1.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7Qg8S7xQe-43",
        "outputId": "a053104c-2515-499c-e9af-46e017e2cceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/dracula1.txt contains 15746 lines, 163955 words and 887239 characters\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "wc data/dracula1.txt | awk '{printf \"%s contains %s lines, %s words and %s characters\\n\", $4, $1, $2, $3}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZJtpWre-43"
      },
      "source": [
        "We can also remove all empty lines using sed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6IW0OSGFe-43",
        "outputId": "02e9311b-68de-4b71-e5fe-1f12ab6a093f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DRACULA\r\n",
            "CHAPTER I\r\n",
            "JONATHAN HARKERS JOURNAL\r\n",
            "(_Kept in shorthand._)\r\n",
            "_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at\r\n",
            "Vienna early next morning; should have arrived at 6:46, but train was an\r\n",
            "hour late. Buda-Pesth seems a wonderful place, from the glimpse which I\r\n",
            "got of it from the train and the little I could walk through the\r\n",
            "streets. I feared to go very far from the station, as we had arrived\r\n",
            "late and would start as near the correct time as possible. The\r\n",
            "impression I had was that we were leaving the West and entering the\r\n",
            "East; the most western of splendid bridges over the Danube, which is\r\n",
            "here of noble width and depth, took us among the traditions of Turkish\r\n",
            "rule.\r\n",
            "We left in pretty good time, and came after nightfall to Klausenburgh.\r\n",
            "Here I stopped for the night at the Hotel Royale. I had for dinner, or\r\n",
            "rather supper, a chicken done up some way with red pepper, which was\r\n",
            "very good but thirsty. (_Mem._, get recipe for Mina.) I asked the\r\n",
            "waiter, and he said it was called paprika hendl, and that, as it was a\r\n",
            "national dish, I should be able to get it anywhere along the\r\n",
            "Carpathians. I found my smattering of German very useful here; indeed, I\r\n",
            "dont know how I should be able to get on without it.\r\n",
            "Having had some time at my disposal when in London, I had visited the\r\n",
            "British Museum, and made search among the books and maps in the library\r\n",
            "regarding Transylvania; it had struck me that some foreknowledge of the\r\n",
            "country could hardly fail to have some importance in dealing with a\r\n",
            "nobleman of that country. I find that the district he named is in the\r\n",
            "extreme east of the country, just on the borders of three states,\r\n",
            "Transylvania, Moldavia and Bukovina, in the midst of the Carpathian\r\n",
            "mountains; one of the wildest and least known portions of Europe. I was\r\n",
            "not able to light on any map or work giving the exact locality of the\r\n",
            "Castle Dracula, as there are no maps of this country as yet to compare\r\n",
            "with our own Ordnance Survey maps; but I found that Bistritz, the post\r\n",
            "town named by Count Dracula, is a fairly well-known place. I shall enter\r\n",
            "here some of my notes, as they may refresh my memory when I talk over my\r\n",
            "travels with Mina.\r\n",
            "In the population of Transylvania there are four distinct nationalities:\r\n",
            "Saxons in the South, and mixed with them the Wallachs, who are the\r\n",
            "descendants of the Dacians; Magyars in the West, and Szekelys in the\r\n",
            "East and North. I am going among the latter, who claim to be descended\r\n",
            "from Attila and the Huns. This may be so, for when the Magyars conquered\r\n",
            "the country in the eleventh century they found the Huns settled in it. I\r\n",
            "read that every known superstition in the world is gathered into the\r\n",
            "horseshoe of the Carpathians, as if it were the centre of some sort of\r\n",
            "imaginative whirlpool; if so my stay may be very interesting. (_Mem._, I\r\n",
            "must ask the Count all about them.)\r\n",
            "I did not sleep well, though my bed was comfortable enough, for I had\r\n",
            "all sorts of queer dreams. There was a dog howling all night under my\r\n",
            "window, which may have had something to do with it; or it may have been\r\n",
            "the paprika, for I had to drink up all the water in my carafe, and was\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "sed -r '/^\\s*$/d' data/dracula1.txt > data/dracula2.txt\n",
        "head -50 data/dracula2.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wc data/dracula2.txt | awk '{printf \"%s contains %s lines, %s words and %s characters\\n\", $4, $1, $2, $3}'"
      ],
      "metadata": {
        "id": "4UEch9GkjRgG",
        "outputId": "8492094b-183d-4a0c-ee97-ea11c3ae2eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/dracula2.txt contains 13307 lines, 163955 words and 882339 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BkePE0Ye-43"
      },
      "source": [
        "Convert all characters to lowercase using tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rsjPRotTe-43",
        "outputId": "e214d41d-5bad-4efa-f8b1-6f1f21b6d33b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dracula\r\n",
            "chapter i\r\n",
            "jonathan harkers journal\r\n",
            "(_kept in shorthand._)\r\n",
            "_3 may. bistritz._--left munich at 8:35 p. m., on 1st may, arriving at\r\n",
            "vienna early next morning; should have arrived at 6:46, but train was an\r\n",
            "hour late. buda-pesth seems a wonderful place, from the glimpse which i\r\n",
            "got of it from the train and the little i could walk through the\r\n",
            "streets. i feared to go very far from the station, as we had arrived\r\n",
            "late and would start as near the correct time as possible. the\r\n",
            "impression i had was that we were leaving the west and entering the\r\n",
            "east; the most western of splendid bridges over the danube, which is\r\n",
            "here of noble width and depth, took us among the traditions of turkish\r\n",
            "rule.\r\n",
            "we left in pretty good time, and came after nightfall to klausenburgh.\r\n",
            "here i stopped for the night at the hotel royale. i had for dinner, or\r\n",
            "rather supper, a chicken done up some way with red pepper, which was\r\n",
            "very good but thirsty. (_mem._, get recipe for mina.) i asked the\r\n",
            "waiter, and he said it was called paprika hendl, and that, as it was a\r\n",
            "national dish, i should be able to get it anywhere along the\r\n",
            "carpathians. i found my smattering of german very useful here; indeed, i\r\n",
            "dont know how i should be able to get on without it.\r\n",
            "having had some time at my disposal when in london, i had visited the\r\n",
            "british museum, and made search among the books and maps in the library\r\n",
            "regarding transylvania; it had struck me that some foreknowledge of the\r\n",
            "country could hardly fail to have some importance in dealing with a\r\n",
            "nobleman of that country. i find that the district he named is in the\r\n",
            "extreme east of the country, just on the borders of three states,\r\n",
            "transylvania, moldavia and bukovina, in the midst of the carpathian\r\n",
            "mountains; one of the wildest and least known portions of europe. i was\r\n",
            "not able to light on any map or work giving the exact locality of the\r\n",
            "castle dracula, as there are no maps of this country as yet to compare\r\n",
            "with our own ordnance survey maps; but i found that bistritz, the post\r\n",
            "town named by count dracula, is a fairly well-known place. i shall enter\r\n",
            "here some of my notes, as they may refresh my memory when i talk over my\r\n",
            "travels with mina.\r\n",
            "in the population of transylvania there are four distinct nationalities:\r\n",
            "saxons in the south, and mixed with them the wallachs, who are the\r\n",
            "descendants of the dacians; magyars in the west, and szekelys in the\r\n",
            "east and north. i am going among the latter, who claim to be descended\r\n",
            "from attila and the huns. this may be so, for when the magyars conquered\r\n",
            "the country in the eleventh century they found the huns settled in it. i\r\n",
            "read that every known superstition in the world is gathered into the\r\n",
            "horseshoe of the carpathians, as if it were the centre of some sort of\r\n",
            "imaginative whirlpool; if so my stay may be very interesting. (_mem._, i\r\n",
            "must ask the count all about them.)\r\n",
            "i did not sleep well, though my bed was comfortable enough, for i had\r\n",
            "all sorts of queer dreams. there was a dog howling all night under my\r\n",
            "window, which may have had something to do with it; or it may have been\r\n",
            "the paprika, for i had to drink up all the water in my carafe, and was\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "tr A-Z a-z <data/dracula2.txt >data/dracula3.txt\n",
        "head -50 data/dracula3.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1UDqbA1e-48"
      },
      "source": [
        "And remove punctuation and numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lIZSiNUue-48",
        "outputId": "0b1daf27-b688-4dad-9e21-8d227fcb47ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dracula\r\n",
            "chapter i\r\n",
            "jonathan harkers journal\r\n",
            "kept in shorthand\r\n",
            " may bistritzleft munich at  p m on st may arriving at\r\n",
            "vienna early next morning should have arrived at  but train was an\r\n",
            "hour late budapesth seems a wonderful place from the glimpse which i\r\n",
            "got of it from the train and the little i could walk through the\r\n",
            "streets i feared to go very far from the station as we had arrived\r\n",
            "late and would start as near the correct time as possible the\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "cat data/dracula3.txt | tr -d [:punct:] | tr -d [:digit:] > data/dracula4.txt\n",
        "head data/dracula4.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vma03ceoe-48"
      },
      "source": [
        "Now we can perform a word frequency analysis using uniq and sort.\n",
        "First we need to substitute spaces with newlines and then sort them to group the same words together. Uniq then will count consecutive lines that are the same and print word frequencies. We reverse sort the result to print most frequent words first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OqgypmBne-48"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# sed -r 's/\\s+/\\n/g' data/dracula4.txt | \\  # Replace spaces with new lines\n",
        "#     awk 'NF' | \\  # another way to remove empty lines\n",
        "#     sort | \\  # alphabetical sort\n",
        "#     uniq -c | \\ # word count\n",
        "#     sort -nr | \\ # reverse numeric sort\n",
        "#     awk '{$1=$1; print}' | \\  # strip leading and trailing whitespace\n",
        "#     awk 'BEGIN { OFS=\"\\t\" } {print $2,$1}' > data/wordcount.txt  # reverse columns\n",
        "\n",
        "\n",
        "sed -r 's/\\s+/\\n/g' data/dracula4.txt | \\\n",
        "   awk 'NF' | \\\n",
        "   sort | \\\n",
        "   uniq -c | \\\n",
        "   sort -nr | \\\n",
        "   awk '{$1=$1; print}' | \\\n",
        "   awk 'BEGIN { OFS=\" \" } {print $2,$1}' > data/wordcount.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tmSA4BRKe-48",
        "outputId": "9d2070bc-cb4b-471a-d481-dc5142a991fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 7983\n",
            "and 5834\n",
            "i 4532\n",
            "to 4527\n",
            "of 3726\n",
            "a 2940\n",
            "in 2533\n",
            "he 2527\n",
            "that 2424\n",
            "it 2062\n",
            "was 1872\n",
            "as 1574\n",
            "for 1519\n",
            "is 1507\n",
            "we 1500\n",
            "his 1464\n",
            "me 1394\n",
            "not 1385\n",
            "you 1364\n",
            "with 1316\n",
            "my 1213\n",
            "all 1145\n",
            "be 1117\n",
            "at 1082\n",
            "on 1074\n",
            "so 1066\n",
            "have 1055\n",
            "her 1044\n",
            "had 1038\n",
            "but 1027\n",
            "him 927\n",
            "she 800\n",
            "when 759\n",
            "there 748\n",
            "which 656\n",
            "this 646\n",
            "if 639\n",
            "from 630\n",
            "are 592\n",
            "said 569\n",
            "were 546\n",
            "by 525\n",
            "or 519\n",
            "then 514\n",
            "could 493\n",
            "one 485\n",
            "do 458\n",
            "them 457\n",
            "us 452\n",
            "they 452\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "head -50 data/wordcount.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO4VylUje-49"
      },
      "source": [
        "\n",
        "We can even create a histogram of word counts using a simple python script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "m83zEUQce-4-"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "function histogram {\n",
        "python3 -c 'import sys\n",
        "for line in sys.stdin:\n",
        "  data, width = line.split()\n",
        "  print(\"{:<15}{:=<{width}}\".format(data, \"\", width=int(int(width) / 75)))' # each = corresponds to a count of 75\n",
        "\n",
        "}\n",
        "export -f histogram\n",
        "\n",
        "cat data/wordcount.txt  | histogram > data/histogram.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "scrolled": true,
        "id": "_f-y9r02e-4_",
        "outputId": "fed2d366-71fc-439d-a5c7-f7412bc0086b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the            ==========================================================================================================\n",
            "and            =============================================================================\n",
            "i              ============================================================\n",
            "to             ============================================================\n",
            "of             =================================================\n",
            "a              =======================================\n",
            "in             =================================\n",
            "he             =================================\n",
            "that           ================================\n",
            "it             ===========================\n",
            "was            ========================\n",
            "as             ====================\n",
            "for            ====================\n",
            "is             ====================\n",
            "we             ====================\n",
            "his            ===================\n",
            "me             ==================\n",
            "not            ==================\n",
            "you            ==================\n",
            "with           =================\n",
            "my             ================\n",
            "all            ===============\n",
            "be             ==============\n",
            "at             ==============\n",
            "on             ==============\n",
            "so             ==============\n",
            "have           ==============\n",
            "her            =============\n",
            "had            =============\n",
            "but            =============\n",
            "him            ============\n",
            "she            ==========\n",
            "when           ==========\n",
            "there          =========\n",
            "which          ========\n",
            "this           ========\n",
            "if             ========\n",
            "from           ========\n",
            "are            =======\n",
            "said           =======\n",
            "were           =======\n",
            "by             =======\n",
            "or             ======\n",
            "then           ======\n",
            "could          ======\n",
            "one            ======\n",
            "do             ======\n",
            "them           ======\n",
            "us             ======\n",
            "they           ======\n",
            "no             =====\n",
            "will           =====\n",
            "must           =====\n",
            "up             =====\n",
            "some           =====\n",
            "what           =====\n",
            "shall          =====\n",
            "would          =====\n",
            "out            =====\n",
            "our            =====\n",
            "may            =====\n",
            "been           =====\n",
            "know           =====\n",
            "see            =====\n",
            "can            =====\n",
            "now            ====\n",
            "more           ====\n",
            "time           ====\n",
            "has            ====\n",
            "am             ====\n",
            "over           ====\n",
            "any            ====\n",
            "van            ====\n",
            "came           ====\n",
            "come           ====\n",
            "your           ====\n",
            "went           ===\n",
            "an             ===\n",
            "helsing        ===\n",
            "into           ===\n",
            "only           ===\n",
            "who            ===\n",
            "very           ===\n",
            "before         ===\n",
            "did            ===\n",
            "like           ===\n",
            "go             ===\n",
            "back           ===\n",
            "down           ===\n",
            "here           ===\n",
            "seemed         ===\n",
            "again          ===\n",
            "about          ===\n",
            "even           ===\n",
            "such           ===\n",
            "took           ==\n",
            "than           ==\n",
            "way            ==\n",
            "their          ==\n",
            "saw            ==\n",
            "though         ==\n",
            "think          ==\n",
            "where          ==\n",
            "much           ==\n",
            "through        ==\n",
            "man            ==\n",
            "dear           ==\n",
            "lucy           ==\n",
            "good           ==\n",
            "after          ==\n",
            "too            ==\n",
            "face           ==\n",
            "hand           ==\n",
            "room           ==\n",
            "night          ==\n",
            "well           ==\n",
            "mina           ==\n",
            "how            ==\n",
            "should         ==\n",
            "made           ==\n",
            "door           ==\n",
            "poor           ==\n",
            "other          ==\n",
            "old            ==\n",
            "own            ==\n",
            "eyes           ==\n",
            "looked         ==\n",
            "tell           ==\n",
            "away           ==\n",
            "work           ==\n",
            "great          ==\n",
            "sleep          ==\n",
            "jonathan       ==\n",
            "get            ==\n",
            "once           ==\n",
            "things         ==\n",
            "i             ==\n",
            "make           ==\n",
            "little         ==\n",
            "dr             ==\n",
            "friend         ==\n",
            "just           ==\n",
            "might          ==\n",
            "look           ==\n",
            "got            ==\n",
            "found          ==\n",
            "day            ==\n",
            "yet            =\n",
            "professor      =\n",
            "off            =\n",
            "long           =\n",
            "count          =\n",
            "thought        =\n",
            "men            =\n",
            "asked          =\n",
            "take           =\n",
            "say            =\n",
            "without        =\n",
            "told           =\n",
            "its            =\n",
            "something      =\n",
            "let            =\n",
            "life           =\n",
            "last           =\n",
            "till           =\n",
            "place          =\n",
            "god            =\n",
            "first          =\n",
            "ever           =\n",
            "heart          =\n",
            "fear           =\n",
            "two            =\n",
            "myself         =\n",
            "knew           =\n",
            "house          =\n",
            "never          =\n",
            "arthur         =\n",
            "done           =\n",
            "himself        =\n",
            "these          =\n",
            "find           =\n",
            "quite          =\n",
            "began          =\n",
            "still          =\n",
            "want           =\n",
            "same           =\n",
            "coming         =\n",
            "nothing        =\n",
            "window         =\n",
            "round          =\n",
            "put            =\n",
            "head           =\n",
            "many           =\n",
            "hands          =\n",
            "harker         =\n",
            "however        =\n",
            "help           =\n",
            "whilst         =\n",
            "mr             =\n",
            "white          =\n",
            "open           =\n",
            "hear           =\n",
            "full           =\n",
            "blood          =\n",
            "mind           =\n",
            "keep           =\n",
            "moment         =\n",
            "thing          =\n",
            "terrible       =\n",
            "left           =\n",
            "right          =\n",
            "anything       =\n",
            "seen           =\n",
            "oh             =\n",
            "rest           =\n",
            "morning        =\n",
            "heard          =\n",
            "upon           =\n",
            "far            =\n",
            "diary          =\n",
            "strange        =\n",
            "madam          =\n",
            "bed            =\n",
            "mrs            =\n",
            "felt           =\n",
            "each           =\n",
            "cannot         =\n",
            "few            =\n",
            "every          =\n",
            "turned         =\n",
            "since          =\n",
            "godalming      =\n",
            "both           =\n",
            "those          =\n",
            "dont          =\n",
            "being          =\n",
            "read           =\n",
            "project        =\n",
            "light          =\n",
            "tonight        =\n",
            "others         =\n",
            "opened         =\n",
            "another        =\n",
            "stood          =\n",
            "give           =\n",
            "sort           =\n",
            "seward         =\n",
            "most           =\n",
            "looking        =\n",
            "alone          =\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "head -250 data/histogram.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW0tinGNe-4_"
      },
      "source": [
        "## Training an n-gram language model\n",
        "\n",
        "Now we can use KenLM to train a 3-gram Language model on our preprocessed corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sF8bQiahe-4_",
        "outputId": "0b7c2f47-b76d-4250-c253-2413ccf5de5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/data/dracula4.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 163034 types 11707\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:140484 2:3786929152 3:7100492288\n",
            "Statistics:\n",
            "1 11707 D1=0.65254 D2=1.02232 D3+=1.40256\n",
            "2 74732 D1=0.777838 D2=1.13233 D3+=1.3484\n",
            "3 134905 D1=0.885782 D2=1.25363 D3+=1.40872\n",
            "Memory estimate for binary LM:\n",
            "type      kB\n",
            "probing 4420 assuming -p 1.5\n",
            "probing 4903 assuming -r models -p 1.5\n",
            "trie    1882 without quantization\n",
            "trie    1077 assuming -q 8 -b 8 quantization \n",
            "trie    1789 assuming -a 22 array pointer compression\n",
            "trie     984 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:140484 2:1195712 3:2698100\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:140484 2:1195712 3:2698100\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10796880 kB\tVmRSS:10228 kB\tRSSMax:2476784 kB\tuser:0.484738\tsys:3.9255\tCPU:4.41028\treal:4.50998\n"
          ]
        }
      ],
      "source": [
        "!lmplz -o 3 <data/dracula4.txt > data/dracula.lm.arpa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2pPpxWfe-4_"
      },
      "source": [
        "We can see some 1-gram, 2-gram and 3-gram scores using grep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "v9tCogcxe-4_",
        "outputId": "ab69ecec-5e71-48e3-d72e-8caa2275cc61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\1-grams:\n",
            "-4.905576\t<unk>\t0\n",
            "0\t<s>\t-0.5739316\n",
            "-1.4011121\t</s>\t0\n",
            "-3.7756853\tdracula\t-0.2081592\n",
            "-4.7675614\tchapter\t-0.109111056\n",
            "-1.8003287\ti\t-0.7904093\n",
            "-2.9896963\tjonathan\t-0.30539653\n",
            "-3.9969275\tharkers\t-0.14176422\n",
            "-3.742329\tjournal\t-0.20828262\n",
            "-3.388833\tkept\t-0.20666325\n",
            "--\n",
            "\\2-grams:\n",
            "-1.6933726\t<s> </s>\t0\n",
            "-0.92340153\tdracula </s>\t0\n",
            "-1.219743\ti </s>\t0\n",
            "-0.9685342\tjonathan </s>\t0\n",
            "-1.425547\tharkers </s>\t0\n",
            "-0.5972116\tjournal </s>\t0\n",
            "-0.96158737\tkept </s>\t0\n",
            "-1.1766673\tin </s>\t0\n",
            "-1.2551455\tshorthand </s>\t0\n",
            "-1.1146483\tmay </s>\t0\n",
            "--\n",
            "\\3-grams:\n",
            "-0.6580499\t<s> dracula </s>\n",
            "-0.84243387\tcastle dracula </s>\n",
            "-0.6578116\tthis dracula </s>\n",
            "-0.6578116\tebook dracula </s>\n",
            "-0.7756664\tchapter i </s>\n",
            "-0.95658225\ti i </s>\n",
            "-1.1548808\tjonathan i </s>\n",
            "-1.2445455\tmay i </s>\n",
            "-0.7756664\tp i </s>\n",
            "-1.0863998\ton i </s>\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "cat data/dracula.lm.arpa | egrep \"1-grams|2-grams|3-grams\" -A10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZFD4ml-e-4_"
      },
      "source": [
        "We can also use query to use the trained language model to score the perplexity of a sentence.\n",
        "Lower perplexity indicates a more probable sentence.\n",
        "\n",
        "Let's have the model score two possible endings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2z0WRRw0e-5A",
        "outputId": "56fb832c-4b79-48be-e6ed-1cfadf3d76f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: invalid option -- 'h'\n",
            "KenLM was compiled with maximum order 6.\n",
            "Usage: query [-b] [-n] [-w] [-s] lm_file\n",
            "-b: Do not buffer output.\n",
            "-n: Do not wrap the input in <s> and </s>.\n",
            "-v summary|sentence|word: Print statistics at this level.\n",
            "   Can be used multiple times: -v summary -v sentence -v word\n",
            "-l lazy|populate|read|parallel: Load lazily, with populate, or malloc+read\n",
            "The default loading method is populate on Linux and read on others.\n",
            "\n",
            "Each word in the output is formatted as:\n",
            "  word=vocab_id ngram_length log10(p(word|context))\n",
            "where ngram_length is the length of n-gram matched.  A vocab_id of 0 indicates\n",
            "the unknown word. Sentence-level output includes log10 probability of the\n",
            "sentence and OOV count.\n"
          ]
        }
      ],
      "source": [
        "!query -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xJ655Zd4e-5A"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "echo \"harker and mina die a horrible death\" > data/bad_ending\n",
        "echo \"harker and mina live happily ever after\" > data/good_ending"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cat data/bad_ending"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pi0mXpTnBme",
        "outputId": "3abbfbd4-0f1b-404b-f4ba-d0579b1defad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harker and mina die a horrible death\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6_2OyMwhe-5A",
        "outputId": "3e434fc4-f4af-4fd7-807c-a02e28b0bcc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity including OOVs:\t461.44070875334245\n"
          ]
        }
      ],
      "source": [
        "!query data/dracula.lm.arpa < data/bad_ending 2>&1| grep \"Perplexity\" | head -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cat data/good_ending"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7RgKoQTnGE5",
        "outputId": "ccd5bc5d-0fd8-4964-9fe2-ee09655acf4a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harker and mina live happily ever after\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yCikajD3e-5A",
        "outputId": "6ac6a64f-bbef-416b-bf71-b76d92de6926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity including OOVs:\t926.7947324237933\n"
          ]
        }
      ],
      "source": [
        "!query data/dracula.lm.arpa < data/good_ending 2>&1| grep \"Perplexity\" | head -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKQ_Akfhe-5A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Bash",
      "language": "bash",
      "name": "bash"
    },
    "language_info": {
      "codemirror_mode": "shell",
      "file_extension": ".sh",
      "mimetype": "text/x-sh",
      "name": "bash"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}